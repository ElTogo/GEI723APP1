{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEI723 — Automne 2025\n",
    "### Neurosciences computationnelles et applications en traitement de l'information\n",
    "\n",
    "Contenu créé par Ismael Balafrej, Ph.D., Jean Rouat, Ph.D. et Ahmad El Ferdaoussi, Ph.D.\n",
    "\n",
    "Ce notebook est une adaptation de la classification par STDP de MNIST par Diehl & Cook. L'article de Diehl & Cook est disponible ici: https://www.frontiersin.org/articles/10.3389/fncom.2015.00099/full\n",
    "\n",
    "Le modèle est simplifié un peu et réécrit pour Brian2 et Python 3. Le code est à trous, et les parties à compléter sont indiquées par 'COMPLETER'.\n",
    "\n",
    "ATTENTION: Dans l'exemple donné ici les auteurs utilisent seulement des données d'entrainement et de validation. Ils utilisent à tort le mot \"test\" pour désigner les données de validation.\n",
    "\n",
    "Les équations et certains paramètres des neurones sont fournies.\n",
    "\n",
    "Un exemple d'encodage par fréquence est utilisé (voir la partie \"testons à présent le réseau entrainé'). Vous avez toute liberté d'utiliser un autre type d'encodage.\n",
    "\n",
    "### Différences avec les travaux de Diehl et Cook et avec l'article\n",
    "La solution python (Brian1) présentée à l'origine sur le github des auteurs de l'article ne reflète pas exactement les équations de l'article. Nous avons par ailleurs converti en Brian 2 une partie de ce code tout en ajoutant certains éléments qui ne sont pas toujours dans l'article (comme par exemple les connexions avec probabilité). À noter qu'une autre version traduite en Brian 2 existe sur le github: https://github.com/zxzhijia/Brian2STDPMNIST .\n",
    "SVP ne tombez pas dans le piège de vouloir absolument reproduire de façon parfaite ces codes informatiques. Ce serait une perte de temps car vous serez interrogé sur votre compréhension de la matière. Passer beaucoup de temps à vouloir remplir un code à trous de façon parfaite ne serait pas intéressant si cette démarche ne vous permet pas de comprendre.\n",
    "\n",
    "Méthode de travail recommandée:\n",
    "- Inplémenter dans un premier temps votre solution selon la compréhension de l'article que vous avez sans vouloir \"coller\" exactement au code à trous. Ceci vous permettra de comprendre l'algorithme de STDP. Dans ce contexte, le code à trous (et les codes disponibles sur internet) sont des éléments pour améliorer votre compréhension et déverminer votre code et non pas pour les \"copier\" tels qu'ils sont.\n",
    "- Ensuite seulement, vous pourrez inclure les variantes proposées dans l'article et/ou dans les codes d'exemples.\n",
    "\n",
    "### Voici les différences et éléments principaux:\n",
    "Le code vous laisse le choix:\n",
    " - de la façon d'initialiser les poids du réseau (vous pouvez ainsi comparer l'impact d'une initialisation aléatoire versus une fixe);\n",
    " - de la façon de présenter les entrées au réseau avec possibilité d'introduire des délais (aléatoires ou fixes) sur les neurones d'entrée;\n",
    " - de normaliser les poids (qui est différente de celle présentée à l'équation (3) de l'article). À noter que dans l'article, les auteurs disent avoir utilisé la normalisation divisive des poids selon les travaux de Goodhill et Barrow.\n",
    " - Créer des connexions avec une probabilité donnée, ce qui peut être utile pour la recherche de réseaux ayant le moins de paramètres possibles à stocker.\n",
    " - Possibilité de choisir le temps de présentation des données.\n",
    " - etc.\n",
    "\n",
    "#### ATTENTION: Ce code est fourni à titre d'exemple. Vous n'avez aucune obligation de résoudre votre problème spécifiquement avec ce code."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, model_selection\n",
    "from brian2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble de données MNIST\n",
    "\n",
    "On télécharge l'ensemble de données MNIST directement dans le code. MNIST est disponible à https://www.openml.org/d/554\n",
    "\n",
    "L'argument 'data_home' peut être utilisé pour télécharger MNIST dans un répertoire de votre choix. (Le répertoire par défaut est '~/scikit_learn_data/'.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "X_all, y_all = datasets.fetch_openml('mnist_784', version=1, return_X_y=True, data_home=\"data\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST est constituté de 70k d'images de 28x28 pixels, de chiffres.\n",
    "\n",
    "'X' est le vecteur d'images, et 'y' est le vecteur d'étiquettes (labels)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "X_all.shape, y_all.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La simulation avec toutes les images est assez longue à faire rouler. Utilisons uniquement un sous-ensemble de MNIST pour une simulation plus rapide."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X = X_all[:10000]\n",
    "y = y_all[:10000]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisons MNIST en ensembles d'entrainement et de test pour entrainer et tester le modèle post-apprentissage.\n",
    "\n",
    "Si on travaille avec l'ensemble au complet, on peut prendre 10k pour le test par exemple."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=100)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessinons une image aléatoire de l'ensemble de données pour voir ce à quoi ressemble MNIST.\n",
    "\n",
    "Les images dans MNIST sont des vecteurs. Il faut donc les ré-organiser en matrice 28x28 pour les afficher."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "index = np.random.randint(0, len(X_train)-1)\n",
    "\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(X_train[index].reshape(28, 28), cmap=plt.cm.gray_r)\n",
    "plt.title(\"Échantillon MNIST avec étiquette %s\" % y_train[index]);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau de neurones Brian2\n",
    "\n",
    "On peut maintenant créer un réseau Brian2. Commençons par définir quelques paramètres."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Fixons le seed aléatoire afin de pouvoir reproduire les résultats\n",
    "np.random.seed(0)\n",
    "\n",
    "# Horloge de Brian2\n",
    "defaultclock.dt = 1 * units.ms\n",
    "\n",
    "# Cible de génération de code pour Brian2\n",
    "prefs.codegen.target = 'cython'\n",
    "\n",
    "time_per_sample =   0.35 * units.second\n",
    "resting_time = 0.15 * units.second\n",
    "\n",
    "v_rest_e = -65. * units.mV\n",
    "v_rest_i = -60. * units.mV\n",
    "\n",
    "v_reset_e = -65. * units.mV\n",
    "v_reset_i = -45. * units.mV\n",
    "\n",
    "v_thresh_e = -52. * units.mV\n",
    "v_thresh_i = -40. * units.mV\n",
    "\n",
    "refrac_e = 5. * units.ms\n",
    "refrac_i = 2. * units.ms\n",
    "\n",
    "tc_theta = 1e7 * units.ms\n",
    "theta_plus_e = 0.10 * units.mV\n",
    "\n",
    "tc_pre_ee = 20 * units.ms\n",
    "tc_post_1_ee = 20 * units.ms\n",
    "tc_post_2_ee = 40 * units.ms\n",
    "\n",
    "# Taux d'apprentissage\n",
    "nu_ee_pre =  0.001\n",
    "nu_ee_post = 0.05"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons l'entrée au réseau de neurones. L'entrée est un encodeur de type codage par fréquence (rate coding)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "input_group = PoissonGroup(784, rates=64*Hz)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons notre modèle de neurone ainsi que nos groupes de neurones."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "neuron_model = '''\n",
    "    dv/dt = ((v_rest_e - v) + (I_synE + I_synI) / nS) / tau  : volt (unless refractory)\n",
    "\n",
    "    I_synE =  ge * nS * -v           : amp\n",
    "    \n",
    "    I_synI =  gi * nS * (d_I_synI-v) : amp\n",
    "    \n",
    "    dge/dt = -ge/(1.0*ms)            : 1\n",
    "    \n",
    "    dgi/dt = -gi/(2.0*ms)            : 1\n",
    "    \n",
    "    tau                              : second (constant, shared)\n",
    "\n",
    "    d_I_synI                         : volt (constant, shared)\n",
    "\n",
    "    dtheta/dt = -theta / (tc_theta)  : volt\n",
    "'''\n",
    "\n",
    "\n",
    "excitatory_group = NeuronGroup(\n",
    "    N=100, model=neuron_model, refractory=refrac_e,\n",
    "    threshold='v > v_thresh_e + theta', reset='v=v_reset_e; theta += theta_plus_e', method='euler')\n",
    "excitatory_group.tau = 100 * units.ms\n",
    "excitatory_group.d_I_synI = -100. * units.mV\n",
    "\n",
    "inhibitory_group = NeuronGroup(\n",
    "    N=100, model=neuron_model, refractory=refrac_i,\n",
    "    threshold='v > v_thresh_i', reset='v=v_reset_i', method='euler')\n",
    "inhibitory_group.tau = 10 * units.ms\n",
    "inhibitory_group.d_I_synI = -85. * mV\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et les synapses."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "synapse_model = \"w : 1\"\n",
    "\n",
    "stdp_synapse_model = '''\n",
    "    w : 1\n",
    "\n",
    "    plastic : boolean (shared) # Activer/désactiver la plasticité\n",
    "    \n",
    "    post2before : 1\n",
    "    \n",
    "    dpre/dt   =   -pre / tc_pre_ee : 1 (event-driven)\n",
    "    \n",
    "    dpost1/dt  = -post1 / tc_post_1_ee : 1 (event-driven)\n",
    "    \n",
    "    dpost2/dt = -post2 / tc_post_2_ee : 1 (event-driven)\n",
    "'''\n",
    "\n",
    "stdp_pre = '''\n",
    "    ge_post += w\n",
    "    \n",
    "    pre = 1.\n",
    "    \n",
    "    w = clip(w + (nu_ee_pre * post1) * int(plastic), 0, 1)\n",
    "'''\n",
    "\n",
    "stdp_post = '''\n",
    "    post2before = post2\n",
    "    \n",
    "    w = clip(w + (nu_ee_post * pre * post2before) * int(plastic), 0, 1)\n",
    "    \n",
    "    post1 = 1.\n",
    "    \n",
    "    post2 = 1.\n",
    "'''\n",
    "\n",
    "input_synapse = Synapses(input_group, excitatory_group, model=stdp_synapse_model, on_pre=stdp_pre, on_post=stdp_post)\n",
    "input_synapse.connect(True) # Fully connected\n",
    "input_synapse.delay = '0*ms'\n",
    "input_synapse.plastic = True\n",
    "\n",
    "# Xavier/Glorot-like initialization for SNNs\n",
    "n_in = 784\n",
    "n_out = 100\n",
    "w_max = 0.25\n",
    "input_synapse.w = f'rand() * {w_max * np.sqrt(2.0 / (n_in + n_out))}'\n",
    "\n",
    "e_i_synapse = Synapses(excitatory_group, inhibitory_group, model=synapse_model, on_pre='ge_post += w')\n",
    "e_i_synapse.connect(p=0.0025)\n",
    "e_i_synapse.w = 'rand()*10.4'\n",
    "\n",
    "i_e_synapse = Synapses(inhibitory_group, excitatory_group, model=synapse_model, on_pre='gi_post += w')\n",
    "i_e_synapse.connect(p=0.9)\n",
    "i_e_synapse.w = 'rand() * 17.0'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Combien de synapses a-t-on dans le réseau?"
  },
  {
   "metadata": {
    "scrolled": true
   },
   "cell_type": "code",
   "source": "print(len(input_synapse) + len(e_i_synapse) + len(i_e_synapse))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Définissons un 'readout' pour notre réseau."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "e_monitor = SpikeMonitor(excitatory_group, record=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Créons le réseau."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "net = Network(input_group, excitatory_group, inhibitory_group,\n",
    "              input_synapse, e_i_synapse, i_e_synapse, e_monitor)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Entrainement\n",
    "\n",
    "Entrainons à présent notre réseau.\n",
    "\n",
    "Créons une matrice 'spikes' pour assigner les étiquettes des classes post-apprentissage. Cette matrice accumulera le décompte de décharges par classe.\n",
    "\n",
    "Notre readout 'e_monitor' est actif tout le long de la simulation avec toutes les images. Donc à chaque nouvelle présentation d'image, on doit soustraire l'ancien décompte de décharges. On utilisera le vecteur 'old_spike_counts' pour le faire."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "spikes = np.zeros((10, len(excitatory_group)))\n",
    "old_spike_counts = np.zeros(len(excitatory_group))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "number_of_epochs = 1\n",
    "\n",
    "for epoch in range(number_of_epochs):  # Fixed: renamed from i to epoch\n",
    "    print('Starting iteration %i' % epoch)\n",
    "    for sample_idx, (sample, label) in enumerate(zip(X_train, y_train)):  # Fixed: renamed from j to sample_idx\n",
    "        # Afficher régulièrement l'état d'avancement\n",
    "        if (sample_idx % 10) == 0:\n",
    "            print(\"Running sample %i out of %i\" % (sample_idx, len(X_train)))\n",
    "\n",
    "        # Configurer le taux d'entrée\n",
    "        input_group.rates = sample / 4 * units.Hz\n",
    "\n",
    "        # Simuler le réseau\n",
    "        net.run(time_per_sample)\n",
    "\n",
    "        # Enregistrer les décharges\n",
    "        spikes[int(label)] += e_monitor.count - old_spike_counts\n",
    "        # Gardons une copie du décompte de décharges pour pouvoir calculer le prochain\n",
    "        old_spike_counts = np.copy(e_monitor.count)\n",
    "\n",
    "        # Arrêter l'entrée\n",
    "        input_group.rates = 0 * units.Hz\n",
    "\n",
    "        # Laisser les variables retourner à leurs valeurs de repos\n",
    "        net.run(resting_time)\n",
    "\n",
    "        # Normaliser les poids\n",
    "\n",
    "        weight_matrix = np.zeros((len(input_group), len(excitatory_group)))\n",
    "        weight_matrix[input_synapse.i, input_synapse.j] = input_synapse.w\n",
    "        colSums = np.sum(weight_matrix, axis=0)\n",
    "        colFactors = 120 / colSums\n",
    "        for neuron_idx in range(len(excitatory_group)):\n",
    "            weight_matrix[:, neuron_idx] *= colFactors[neuron_idx]\n",
    "        input_synapse.w = weight_matrix[input_synapse.i, input_synapse.j]\n",
    "        if sample_idx % 200 == 0:\n",
    "            weight_matrix = np.zeros((784, len(excitatory_group)))\n",
    "            weight_matrix[input_synapse.i, input_synapse.j] = input_synapse.w\n",
    "\n",
    "            plt.figure(figsize=(10, 10))  # Larger figure for more neurons\n",
    "            for i in range(min(100, len(excitatory_group))):  # Changed from 100 to 400\n",
    "                plt.subplot(10, 10, i+1)  # Changed from 10x10 to 20x20 grid\n",
    "                plt.imshow(weight_matrix[:, i].reshape(28, 28), cmap='gray')\n",
    "                plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test\n",
    "\n",
    "Commençons par trouver le meilleur neurone pour chaque classe de MNIST."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''input_synapse.plastic = False  # Turn off learning\n",
    "excitatory_group.theta = 0 * units.mV\n",
    "\n",
    "assignment_spikes = np.zeros((10, len(excitatory_group)))\n",
    "old_spike_counts = np.zeros(len(excitatory_group))\n",
    "\n",
    "num_assignment_samples = 10  # per digit\n",
    "for digit in range(10):\n",
    "\n",
    "    # Get samples of this digit\n",
    "    digit_indices = np.where(y_train == str(digit))[0][:num_assignment_samples]\n",
    "\n",
    "    for idx in digit_indices:\n",
    "        sample = X_train[idx]\n",
    "\n",
    "        # Reset state for clean measurement\n",
    "        excitatory_group.theta = 0 * units.mV\n",
    "\n",
    "        input_group.rates = sample / 2 * units.Hz\n",
    "        net.run(time_per_sample)\n",
    "\n",
    "        # Count spikes for this digit\n",
    "        assignment_spikes[digit] += e_monitor.count - old_spike_counts\n",
    "        old_spike_counts = np.copy(e_monitor.count)\n",
    "\n",
    "        input_group.rates = 0 * units.Hz\n",
    "        net.run(resting_time)\n",
    "\n",
    "# Assign each neuron to digit it fired most for\n",
    "assignment_spikes[0] = assignment_spikes[0]*0.1*0.1\n",
    "neuron_assignments = np.argmax(assignment_spikes, axis=0)\n",
    "mostLabelNeuron = np.argmax(assignment_spikes, axis=1)'''"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Testons à présent le réseau entrainé!"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "labeled_neurons = np.argmax(spikes, axis=0)\n",
    "print(\"Neurones assignés aux classes:\", labeled_neurons)\n",
    "from collections import Counter\n",
    "counts = Counter(neuron_assignments)\n",
    "for digit in range(10):\n",
    "    print(f\"Chiffre {digit}: {counts.get(digit, 0)} neurones\")\n",
    "# 1. Visualiser les poids\n",
    "weight_matrix = np.zeros((784, len(excitatory_group)))\n",
    "weight_matrix[input_synapse.i, input_synapse.j] = input_synapse.w\n",
    "\n",
    "plt.figure(figsize=(10, 10))  # Larger figure for more neurons\n",
    "for i in range(min(200, len(excitatory_group))):  # Changed from 100 to 400\n",
    "    plt.subplot(10, 10, i+1)  # Changed from 10x10 to 20x20 grid\n",
    "    plt.imshow(weight_matrix[:, i].reshape(28, 28), cmap='gray')\n",
    "    #plt.title(f'N{i}: {neuron_assignments[i]}', fontsize=10, pad=2)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(weight_matrix[:28*28, :200], cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(spikes.sum(axis=1))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Déasctiver la plasticité STDP\n",
    "input_synapse.plastic = False\n",
    "\n",
    "num_correct_output = 0\n",
    "\n",
    "for i, (sample, label) in enumerate(zip(X_test, y_test)):\n",
    "    # Afficher régulièrement l'état d'avancement\n",
    "    if (i % 10) == 0:\n",
    "        print(\"Running sample %i out of %i\" % (i, len(X_test)))\n",
    "\n",
    "    # Configurer le taux d'entrée\n",
    "    # ATTENTION, vous pouvez utiliser un autre type d'encodage\n",
    "    input_group.rates = sample / 4 * units.Hz\n",
    "\n",
    "    # Simuler le réseau\n",
    "    net.run(time_per_sample)\n",
    "\n",
    "    # Calculer le nombre de décharges pour l'échantillon\n",
    "    current_spike_count = e_monitor.count - old_spike_counts\n",
    "    # Gardons une copie du décompte de décharges pour pouvoir calculer le prochain\n",
    "    old_spike_counts = np.copy(e_monitor.count)\n",
    "\n",
    "    class_responses = np.array([np.sum(current_spike_count[labeled_neurons == c])\n",
    "                            for c in range(10)])\n",
    "    output_label = np.argmax(class_responses)\n",
    "\n",
    "    # Si la prédiction est correcte\n",
    "    if output_label == int(label):\n",
    "        num_correct_output += 1\n",
    "\n",
    "    # Laisser les variables retourner à leurs valeurs de repos\n",
    "    net.run(resting_time)\n",
    "\n",
    "\n",
    "print(\"The model accuracy is : %.3f\" % (num_correct_output / len(X_test)))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
