{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEI723 — Automne 2025\n",
    "### Neurosciences computationnelles et applications en traitement de l'information\n",
    "\n",
    "Contenu créé par Ismael Balafrej, Ph.D., Jean Rouat, Ph.D. et Ahmad El Ferdaoussi, Ph.D.\n",
    "\n",
    "Ce notebook est une adaptation de la classification par STDP de MNIST par Diehl & Cook. L'article de Diehl & Cook est disponible ici: https://www.frontiersin.org/articles/10.3389/fncom.2015.00099/full\n",
    "\n",
    "Le modèle est simplifié un peu et réécrit pour Brian2 et Python 3. Le code est à trous, et les parties à compléter sont indiquées par 'COMPLETER'.\n",
    "\n",
    "ATTENTION: Dans l'exemple donné ici les auteurs utilisent seulement des données d'entrainement et de validation. Ils utilisent à tort le mot \"test\" pour désigner les données de validation.\n",
    "\n",
    "Les équations et certains paramètres des neurones sont fournies.\n",
    "\n",
    "Un exemple d'encodage par fréquence est utilisé (voir la partie \"testons à présent le réseau entrainé'). Vous avez toute liberté d'utiliser un autre type d'encodage.\n",
    "\n",
    "### Différences avec les travaux de Diehl et Cook et avec l'article\n",
    "La solution python (Brian1) présentée à l'origine sur le github des auteurs de l'article ne reflète pas exactement les équations de l'article. Nous avons par ailleurs converti en Brian 2 une partie de ce code tout en ajoutant certains éléments qui ne sont pas toujours dans l'article (comme par exemple les connexions avec probabilité). À noter qu'une autre version traduite en Brian 2 existe sur le github: https://github.com/zxzhijia/Brian2STDPMNIST .\n",
    "SVP ne tombez pas dans le piège de vouloir absolument reproduire de façon parfaite ces codes informatiques. Ce serait une perte de temps car vous serez interrogé sur votre compréhension de la matière. Passer beaucoup de temps à vouloir remplir un code à trous de façon parfaite ne serait pas intéressant si cette démarche ne vous permet pas de comprendre.\n",
    "\n",
    "Méthode de travail recommandée:\n",
    "- Inplémenter dans un premier temps votre solution selon la compréhension de l'article que vous avez sans vouloir \"coller\" exactement au code à trous. Ceci vous permettra de comprendre l'algorithme de STDP. Dans ce contexte, le code à trous (et les codes disponibles sur internet) sont des éléments pour améliorer votre compréhension et déverminer votre code et non pas pour les \"copier\" tels qu'ils sont.\n",
    "- Ensuite seulement, vous pourrez inclure les variantes proposées dans l'article et/ou dans les codes d'exemples.\n",
    "\n",
    "### Voici les différences et éléments principaux:\n",
    "Le code vous laisse le choix:\n",
    " - de la façon d'initialiser les poids du réseau (vous pouvez ainsi comparer l'impact d'une initialisation aléatoire versus une fixe);\n",
    " - de la façon de présenter les entrées au réseau avec possibilité d'introduire des délais (aléatoires ou fixes) sur les neurones d'entrée;\n",
    " - de normaliser les poids (qui est différente de celle présentée à l'équation (3) de l'article). À noter que dans l'article, les auteurs disent avoir utilisé la normalisation divisive des poids selon les travaux de Goodhill et Barrow.\n",
    " - Créer des connexions avec une probabilité donnée, ce qui peut être utile pour la recherche de réseaux ayant le moins de paramètres possibles à stocker.\n",
    " - Possibilité de choisir le temps de présentation des données.\n",
    " - etc.\n",
    "\n",
    "#### ATTENTION: Ce code est fourni à titre d'exemple. Vous n'avez aucune obligation de résoudre votre problème spécifiquement avec ce code."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:48:55.786477Z",
     "start_time": "2025-11-12T04:48:54.595337Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, model_selection\n",
    "from brian2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble de données MNIST\n",
    "\n",
    "On télécharge l'ensemble de données MNIST directement dans le code. MNIST est disponible à https://www.openml.org/d/554\n",
    "\n",
    "L'argument 'data_home' peut être utilisé pour télécharger MNIST dans un répertoire de votre choix. (Le répertoire par défaut est '~/scikit_learn_data/'.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:48:57.216040Z",
     "start_time": "2025-11-12T04:48:55.789478Z"
    }
   },
   "source": "X_all, y_all = datasets.fetch_openml('mnist_784', version=1, return_X_y=True, data_home=\"data\")",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST est constituté de 70k d'images de 28x28 pixels, de chiffres.\n",
    "\n",
    "'X' est le vecteur d'images, et 'y' est le vecteur d'étiquettes (labels)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-11-12T04:48:57.919536Z",
     "start_time": "2025-11-12T04:48:57.907537Z"
    }
   },
   "source": [
    "X_all.shape, y_all.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La simulation avec toutes les images est assez longue à faire rouler. Utilisons uniquement un sous-ensemble de MNIST pour une simulation plus rapide."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:48:57.935534Z",
     "start_time": "2025-11-12T04:48:57.929536Z"
    }
   },
   "source": [
    "X = X_all[:10000]\n",
    "y = y_all[:10000]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisons MNIST en ensembles d'entrainement et de test pour entrainer et tester le modèle post-apprentissage.\n",
    "\n",
    "Si on travaille avec l'ensemble au complet, on peut prendre 10k pour le test par exemple."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:48:57.966532Z",
     "start_time": "2025-11-12T04:48:57.943535Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=1000)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessinons une image aléatoire de l'ensemble de données pour voir ce à quoi ressemble MNIST.\n",
    "\n",
    "Les images dans MNIST sont des vecteurs. Il faut donc les ré-organiser en matrice 28x28 pour les afficher."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:48:58.013622Z",
     "start_time": "2025-11-12T04:48:57.969534Z"
    }
   },
   "source": [
    "index = np.random.randint(0, len(X_train)-1)\n",
    "\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(X_train[index].reshape(28, 28), cmap=plt.cm.gray_r)\n",
    "plt.title(\"Échantillon MNIST avec étiquette %s\" % y_train[index]);"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau de neurones Brian2\n",
    "\n",
    "On peut maintenant créer un réseau Brian2. Commençons par définir quelques paramètres."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:48:58.029622Z",
     "start_time": "2025-11-12T04:48:58.016624Z"
    }
   },
   "source": [
    "# Fixons le seed aléatoire afin de pouvoir reproduire les résultats\n",
    "np.random.seed(0)\n",
    "\n",
    "# Horloge de Brian2\n",
    "defaultclock.dt = 1 * units.ms\n",
    "\n",
    "# Cible de génération de code pour Brian2\n",
    "prefs.codegen.target = 'cython'\n",
    "\n",
    "time_per_sample =   0.35 * units.second\n",
    "resting_time = 0.15 * units.second\n",
    "\n",
    "v_rest_e = -65. * units.mV\n",
    "v_rest_i = -60. * units.mV\n",
    "\n",
    "v_reset_e = -65. * units.mV\n",
    "v_reset_i = -45. * units.mV\n",
    "\n",
    "v_thresh_e = -52. * units.mV\n",
    "v_thresh_i = -40. * units.mV\n",
    "\n",
    "refrac_e = 5. * units.ms\n",
    "refrac_i = 2. * units.ms\n",
    "\n",
    "tc_theta = 1e5 * units.ms\n",
    "theta_plus_e = 0.05 * units.mV\n",
    "\n",
    "tc_pre_ee = 20 * units.ms\n",
    "tc_post_1_ee = 20 * units.ms\n",
    "tc_post_2_ee = 40 * units.ms\n",
    "\n",
    "# Taux d'apprentissage\n",
    "nu_ee_pre =  0.001\n",
    "nu_ee_post = 0.01"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons l'entrée au réseau de neurones. L'entrée est un encodeur de type codage par fréquence (rate coding)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:48:58.045639Z",
     "start_time": "2025-11-12T04:48:58.032626Z"
    }
   },
   "source": "input_group = PoissonGroup(784, rates=64*Hz)",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons notre modèle de neurone ainsi que nos groupes de neurones."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:48:58.061641Z",
     "start_time": "2025-11-12T04:48:58.047643Z"
    }
   },
   "source": [
    "neuron_model = '''\n",
    "    dv/dt = ((v_rest_e - v) + (I_synE + I_synI) / nS) / tau  : volt (unless refractory)\n",
    "\n",
    "    I_synE =  ge * nS * -v           : amp\n",
    "    \n",
    "    I_synI =  gi * nS * (d_I_synI-v) : amp\n",
    "    \n",
    "    dge/dt = -ge/(1.0*ms)            : 1\n",
    "    \n",
    "    dgi/dt = -gi/(2.0*ms)            : 1\n",
    "    \n",
    "    tau                              : second (constant, shared)\n",
    "    \n",
    "    d_I_synI                         : volt (constant, shared)\n",
    "    \n",
    "    dtheta/dt = -theta / (tc_theta)  : volt\n",
    "'''\n",
    "\n",
    "excitatory_group = NeuronGroup(\n",
    "    N=400, model=neuron_model, refractory=refrac_e,\n",
    "    threshold='v > v_thresh_e + theta', reset='v=v_reset_e; theta += theta_plus_e', method='euler')\n",
    "excitatory_group.tau = 100 * units.ms\n",
    "excitatory_group.d_I_synI = -100. * units.mV\n",
    "\n",
    "inhibitory_group = NeuronGroup(\n",
    "    N=400, model=neuron_model, refractory=refrac_i,\n",
    "    threshold='v > v_thresh_i', reset='v=v_reset_i', method='euler')\n",
    "inhibitory_group.tau = 10 * units.ms\n",
    "inhibitory_group.d_I_synI = -85. * mV"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et les synapses."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:49:01.480216Z",
     "start_time": "2025-11-12T04:48:58.063642Z"
    }
   },
   "source": [
    "synapse_model = \"w : 1\"\n",
    "\n",
    "stdp_synapse_model = '''\n",
    "    w : 1\n",
    "\n",
    "    plastic : boolean (shared) # Activer/désactiver la plasticité\n",
    "    \n",
    "    post2before : 1\n",
    "    \n",
    "    dpre/dt   =   -pre / tc_pre_ee : 1 (event-driven)\n",
    "    \n",
    "    dpost1/dt  = -post1 / tc_post_1_ee : 1 (event-driven)\n",
    "    \n",
    "    dpost2/dt = -post2 / tc_post_2_ee : 1 (event-driven)\n",
    "'''\n",
    "\n",
    "stdp_pre = '''\n",
    "    ge_post += w\n",
    "    \n",
    "    pre = 1.\n",
    "    \n",
    "    w = clip(w + (nu_ee_pre * post1) * int(plastic), 0, 1)\n",
    "'''\n",
    "\n",
    "stdp_post = '''\n",
    "    post2before = post2\n",
    "    \n",
    "    w = clip(w + (nu_ee_post * pre * post2before) * int(plastic), 0, 1)\n",
    "    \n",
    "    post1 = 1.\n",
    "    \n",
    "    post2 = 1.\n",
    "'''\n",
    "\n",
    "input_synapse = Synapses(input_group, excitatory_group, model=stdp_synapse_model, on_pre=stdp_pre, on_post=stdp_post)\n",
    "input_synapse.connect(True) # Fully connected\n",
    "input_synapse.delay = 'clip(5*ms + randn()*2*ms, 0.5*ms, 15*ms)'\n",
    "input_synapse.plastic = True\n",
    "# Xavier/Glorot-like initialization for SNNs\n",
    "n_in = 784\n",
    "n_out = 100\n",
    "w_max = 0.5\n",
    "input_synapse.w = f'rand() * {w_max * np.sqrt(2.0 / (n_in + n_out))}'\n",
    "\n",
    "e_i_synapse = Synapses(excitatory_group, inhibitory_group, model=synapse_model, on_pre='ge_post += w')\n",
    "e_i_synapse.connect(j='i')\n",
    "e_i_synapse.w = 'rand()*10.4'\n",
    "\n",
    "i_e_synapse = Synapses(inhibitory_group, excitatory_group, model=synapse_model, on_pre='gi_post += w')\n",
    "i_e_synapse.connect(p=0.7, condition='i != j')\n",
    "i_e_synapse.w = 'rand()*12.0'"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Combien de synapses a-t-on dans le réseau?"
  },
  {
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-11-12T04:49:02.173863Z",
     "start_time": "2025-11-12T04:49:02.159862Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(input_synapse) + len(e_i_synapse) + len(i_e_synapse))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425504\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Définissons un 'readout' pour notre réseau."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:49:02.189861Z",
     "start_time": "2025-11-12T04:49:02.176863Z"
    }
   },
   "cell_type": "code",
   "source": "e_monitor = SpikeMonitor(excitatory_group, record=True)",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Créons le réseau."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:49:02.204616Z",
     "start_time": "2025-11-12T04:49:02.191861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = Network(input_group, excitatory_group, inhibitory_group,\n",
    "              input_synapse, e_i_synapse, i_e_synapse, e_monitor)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Entrainement\n",
    "\n",
    "Entrainons à présent notre réseau.\n",
    "\n",
    "Créons une matrice 'spikes' pour assigner les étiquettes des classes post-apprentissage. Cette matrice accumulera le décompte de décharges par classe.\n",
    "\n",
    "Notre readout 'e_monitor' est actif tout le long de la simulation avec toutes les images. Donc à chaque nouvelle présentation d'image, on doit soustraire l'ancien décompte de décharges. On utilisera le vecteur 'old_spike_counts' pour le faire."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:49:02.220052Z",
     "start_time": "2025-11-12T04:49:02.206621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spikes = np.zeros((10, len(excitatory_group)))\n",
    "old_spike_counts = np.zeros(len(excitatory_group))\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-12T04:49:02.222053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_of_epochs = 10\n",
    "\n",
    "for epoch in range(number_of_epochs):  # Fixed: renamed from i to epoch\n",
    "    print('Starting iteration %i' % epoch)\n",
    "    for sample_idx, (sample, label) in enumerate(zip(X_train, y_train)):  # Fixed: renamed from j to sample_idx\n",
    "        # Afficher régulièrement l'état d'avancement\n",
    "        if (sample_idx % 10) == 0:\n",
    "            print(\"Running sample %i out of %i\" % (sample_idx, len(X_train)))\n",
    "\n",
    "        # Configurer le taux d'entrée\n",
    "        input_group.rates = sample / 4 * units.Hz\n",
    "\n",
    "        # Simuler le réseau\n",
    "        net.run(time_per_sample)\n",
    "\n",
    "        # Enregistrer les décharges\n",
    "        spikes[int(label)] += e_monitor.count - old_spike_counts\n",
    "        # Gardons une copie du décompte de décharges pour pouvoir calculer le prochain\n",
    "        old_spike_counts = np.copy(e_monitor.count)\n",
    "\n",
    "        # Arrêter l'entrée\n",
    "        input_group.rates = 0 * units.Hz\n",
    "\n",
    "        # Laisser les variables retourner à leurs valeurs de repos\n",
    "        net.run(resting_time)\n",
    "\n",
    "        # Normaliser les poids\n",
    "        if sample_idx % 10 == 0:\n",
    "            weight_matrix = np.zeros((len(input_group), len(excitatory_group)))\n",
    "            weight_matrix[input_synapse.i, input_synapse.j] = input_synapse.w\n",
    "            colSums = np.sum(weight_matrix, axis=0)\n",
    "            colFactors = 78.4 / colSums\n",
    "            for neuron_idx in range(len(excitatory_group)):\n",
    "                weight_matrix[:, neuron_idx] *= colFactors[neuron_idx]\n",
    "            input_synapse.w = weight_matrix[input_synapse.i, input_synapse.j]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "Running sample 0 out of 9000\n",
      "Running sample 10 out of 9000\n",
      "Running sample 20 out of 9000\n",
      "Running sample 30 out of 9000\n",
      "Running sample 40 out of 9000\n",
      "Running sample 50 out of 9000\n",
      "Running sample 60 out of 9000\n",
      "Running sample 70 out of 9000\n",
      "Running sample 80 out of 9000\n",
      "Running sample 90 out of 9000\n",
      "Running sample 100 out of 9000\n",
      "Running sample 110 out of 9000\n",
      "Running sample 120 out of 9000\n",
      "Running sample 130 out of 9000\n",
      "Running sample 140 out of 9000\n",
      "Running sample 150 out of 9000\n",
      "Running sample 160 out of 9000\n",
      "Running sample 170 out of 9000\n",
      "Running sample 180 out of 9000\n",
      "Running sample 190 out of 9000\n",
      "Running sample 200 out of 9000\n",
      "Running sample 210 out of 9000\n",
      "Running sample 220 out of 9000\n",
      "Running sample 230 out of 9000\n",
      "Running sample 240 out of 9000\n",
      "Running sample 250 out of 9000\n",
      "Running sample 260 out of 9000\n",
      "Running sample 270 out of 9000\n",
      "Running sample 280 out of 9000\n",
      "Running sample 290 out of 9000\n",
      "Running sample 300 out of 9000\n",
      "Running sample 310 out of 9000\n",
      "Running sample 320 out of 9000\n",
      "Running sample 330 out of 9000\n",
      "Running sample 340 out of 9000\n",
      "Running sample 350 out of 9000\n",
      "Running sample 360 out of 9000\n",
      "Running sample 370 out of 9000\n",
      "Running sample 380 out of 9000\n",
      "Running sample 390 out of 9000\n",
      "Running sample 400 out of 9000\n",
      "Running sample 410 out of 9000\n",
      "Running sample 420 out of 9000\n",
      "Running sample 430 out of 9000\n",
      "Running sample 440 out of 9000\n",
      "Running sample 450 out of 9000\n",
      "Running sample 460 out of 9000\n",
      "Running sample 470 out of 9000\n",
      "Running sample 480 out of 9000\n",
      "Running sample 490 out of 9000\n",
      "Running sample 500 out of 9000\n",
      "Running sample 510 out of 9000\n",
      "Running sample 520 out of 9000\n",
      "Running sample 530 out of 9000\n",
      "Running sample 540 out of 9000\n",
      "Running sample 550 out of 9000\n",
      "Running sample 560 out of 9000\n",
      "Running sample 570 out of 9000\n",
      "Running sample 580 out of 9000\n",
      "Running sample 590 out of 9000\n",
      "Running sample 600 out of 9000\n",
      "Running sample 610 out of 9000\n",
      "Running sample 620 out of 9000\n",
      "Running sample 630 out of 9000\n",
      "Running sample 640 out of 9000\n",
      "Running sample 650 out of 9000\n",
      "Running sample 660 out of 9000\n",
      "Running sample 670 out of 9000\n",
      "Running sample 680 out of 9000\n",
      "Running sample 690 out of 9000\n",
      "Running sample 700 out of 9000\n",
      "Running sample 710 out of 9000\n",
      "Running sample 720 out of 9000\n",
      "Running sample 730 out of 9000\n",
      "Running sample 740 out of 9000\n",
      "Running sample 750 out of 9000\n",
      "Running sample 760 out of 9000\n",
      "Running sample 770 out of 9000\n",
      "Running sample 780 out of 9000\n",
      "Running sample 790 out of 9000\n",
      "Running sample 800 out of 9000\n",
      "Running sample 810 out of 9000\n",
      "Running sample 820 out of 9000\n",
      "Running sample 830 out of 9000\n",
      "Running sample 840 out of 9000\n",
      "Running sample 850 out of 9000\n",
      "Running sample 860 out of 9000\n",
      "Running sample 870 out of 9000\n",
      "Running sample 880 out of 9000\n",
      "Running sample 890 out of 9000\n",
      "Running sample 900 out of 9000\n",
      "Running sample 910 out of 9000\n",
      "Running sample 920 out of 9000\n",
      "Running sample 930 out of 9000\n",
      "Running sample 940 out of 9000\n",
      "Running sample 950 out of 9000\n",
      "Running sample 960 out of 9000\n",
      "Running sample 970 out of 9000\n",
      "Running sample 980 out of 9000\n",
      "Running sample 990 out of 9000\n",
      "Running sample 1000 out of 9000\n",
      "Running sample 1010 out of 9000\n",
      "Running sample 1020 out of 9000\n",
      "Running sample 1030 out of 9000\n",
      "Running sample 1040 out of 9000\n",
      "Running sample 1050 out of 9000\n",
      "Running sample 1060 out of 9000\n",
      "Running sample 1070 out of 9000\n",
      "Running sample 1080 out of 9000\n",
      "Running sample 1090 out of 9000\n",
      "Running sample 1100 out of 9000\n",
      "Running sample 1110 out of 9000\n",
      "Running sample 1120 out of 9000\n",
      "Running sample 1130 out of 9000\n",
      "Running sample 1140 out of 9000\n",
      "Running sample 1150 out of 9000\n",
      "Running sample 1160 out of 9000\n",
      "Running sample 1170 out of 9000\n",
      "Running sample 1180 out of 9000\n",
      "Running sample 1190 out of 9000\n",
      "Running sample 1200 out of 9000\n",
      "Running sample 1210 out of 9000\n",
      "Running sample 1220 out of 9000\n",
      "Running sample 1230 out of 9000\n",
      "Running sample 1240 out of 9000\n",
      "Running sample 1250 out of 9000\n",
      "Running sample 1260 out of 9000\n",
      "Running sample 1270 out of 9000\n",
      "Running sample 1280 out of 9000\n",
      "Running sample 1290 out of 9000\n",
      "Running sample 1300 out of 9000\n",
      "Running sample 1310 out of 9000\n",
      "Running sample 1320 out of 9000\n",
      "Running sample 1330 out of 9000\n",
      "Running sample 1340 out of 9000\n",
      "Running sample 1350 out of 9000\n",
      "Running sample 1360 out of 9000\n",
      "Running sample 1370 out of 9000\n",
      "Running sample 1380 out of 9000\n",
      "Running sample 1390 out of 9000\n",
      "Running sample 1400 out of 9000\n",
      "Running sample 1410 out of 9000\n",
      "Running sample 1420 out of 9000\n",
      "Running sample 1430 out of 9000\n",
      "Running sample 1440 out of 9000\n",
      "Running sample 1450 out of 9000\n",
      "Running sample 1460 out of 9000\n",
      "Running sample 1470 out of 9000\n",
      "Running sample 1480 out of 9000\n",
      "Running sample 1490 out of 9000\n",
      "Running sample 1500 out of 9000\n",
      "Running sample 1510 out of 9000\n",
      "Running sample 1520 out of 9000\n",
      "Running sample 1530 out of 9000\n",
      "Running sample 1540 out of 9000\n",
      "Running sample 1550 out of 9000\n",
      "Running sample 1560 out of 9000\n",
      "Running sample 1570 out of 9000\n",
      "Running sample 1580 out of 9000\n",
      "Running sample 1590 out of 9000\n",
      "Running sample 1600 out of 9000\n",
      "Running sample 1610 out of 9000\n",
      "Running sample 1620 out of 9000\n",
      "Running sample 1630 out of 9000\n",
      "Running sample 1640 out of 9000\n",
      "Running sample 1650 out of 9000\n",
      "Running sample 1660 out of 9000\n",
      "Running sample 1670 out of 9000\n",
      "Running sample 1680 out of 9000\n",
      "Running sample 1690 out of 9000\n",
      "Running sample 1700 out of 9000\n",
      "Running sample 1710 out of 9000\n",
      "Running sample 1720 out of 9000\n",
      "Running sample 1730 out of 9000\n",
      "Running sample 1740 out of 9000\n",
      "Running sample 1750 out of 9000\n",
      "Running sample 1760 out of 9000\n",
      "Running sample 1770 out of 9000\n",
      "Running sample 1780 out of 9000\n",
      "Running sample 1790 out of 9000\n",
      "Running sample 1800 out of 9000\n",
      "Running sample 1810 out of 9000\n",
      "Running sample 1820 out of 9000\n",
      "Running sample 1830 out of 9000\n",
      "Running sample 1840 out of 9000\n",
      "Running sample 1850 out of 9000\n",
      "Running sample 1860 out of 9000\n",
      "Running sample 1870 out of 9000\n",
      "Running sample 1880 out of 9000\n",
      "Running sample 1890 out of 9000\n",
      "Running sample 1900 out of 9000\n",
      "Running sample 1910 out of 9000\n",
      "Running sample 1920 out of 9000\n",
      "Running sample 1930 out of 9000\n",
      "Running sample 1940 out of 9000\n",
      "Running sample 1950 out of 9000\n",
      "Running sample 1960 out of 9000\n",
      "Running sample 1970 out of 9000\n",
      "Running sample 1980 out of 9000\n",
      "Running sample 1990 out of 9000\n",
      "Running sample 2000 out of 9000\n",
      "Running sample 2010 out of 9000\n",
      "Running sample 2020 out of 9000\n",
      "Running sample 2030 out of 9000\n",
      "Running sample 2040 out of 9000\n",
      "Running sample 2050 out of 9000\n",
      "Running sample 2060 out of 9000\n",
      "Running sample 2070 out of 9000\n",
      "Running sample 2080 out of 9000\n",
      "Running sample 2090 out of 9000\n",
      "Running sample 2100 out of 9000\n",
      "Running sample 2110 out of 9000\n",
      "Running sample 2120 out of 9000\n",
      "Running sample 2130 out of 9000\n",
      "Running sample 2140 out of 9000\n",
      "Running sample 2150 out of 9000\n",
      "Running sample 2160 out of 9000\n",
      "Running sample 2170 out of 9000\n",
      "Running sample 2180 out of 9000\n",
      "Running sample 2190 out of 9000\n",
      "Running sample 2200 out of 9000\n",
      "Running sample 2210 out of 9000\n",
      "Running sample 2220 out of 9000\n",
      "Running sample 2230 out of 9000\n",
      "Running sample 2240 out of 9000\n",
      "Running sample 2250 out of 9000\n",
      "Running sample 2260 out of 9000\n",
      "Running sample 2270 out of 9000\n",
      "Running sample 2280 out of 9000\n",
      "Running sample 2290 out of 9000\n",
      "Running sample 2300 out of 9000\n",
      "Running sample 2310 out of 9000\n",
      "Running sample 2320 out of 9000\n",
      "Running sample 2330 out of 9000\n",
      "Running sample 2340 out of 9000\n",
      "Running sample 2350 out of 9000\n",
      "Running sample 2360 out of 9000\n",
      "Running sample 2370 out of 9000\n",
      "Running sample 2380 out of 9000\n",
      "Running sample 2390 out of 9000\n",
      "Running sample 2400 out of 9000\n",
      "Running sample 2410 out of 9000\n",
      "Running sample 2420 out of 9000\n",
      "Running sample 2430 out of 9000\n",
      "Running sample 2440 out of 9000\n",
      "Running sample 2450 out of 9000\n",
      "Running sample 2460 out of 9000\n",
      "Running sample 2470 out of 9000\n",
      "Running sample 2480 out of 9000\n",
      "Running sample 2490 out of 9000\n",
      "Running sample 2500 out of 9000\n",
      "Running sample 2510 out of 9000\n",
      "Running sample 2520 out of 9000\n",
      "Running sample 2530 out of 9000\n",
      "Running sample 2540 out of 9000\n",
      "Running sample 2550 out of 9000\n",
      "Running sample 2560 out of 9000\n",
      "Running sample 2570 out of 9000\n",
      "Running sample 2580 out of 9000\n",
      "Running sample 2590 out of 9000\n",
      "Running sample 2600 out of 9000\n",
      "Running sample 2610 out of 9000\n",
      "Running sample 2620 out of 9000\n",
      "Running sample 2630 out of 9000\n",
      "Running sample 2640 out of 9000\n",
      "Running sample 2650 out of 9000\n",
      "Running sample 2660 out of 9000\n",
      "Running sample 2670 out of 9000\n",
      "Running sample 2680 out of 9000\n",
      "Running sample 2690 out of 9000\n",
      "Running sample 2700 out of 9000\n",
      "Running sample 2710 out of 9000\n",
      "Running sample 2720 out of 9000\n",
      "Running sample 2730 out of 9000\n",
      "Running sample 2740 out of 9000\n",
      "Running sample 2750 out of 9000\n",
      "Running sample 2760 out of 9000\n",
      "Running sample 2770 out of 9000\n",
      "Running sample 2780 out of 9000\n",
      "Running sample 2790 out of 9000\n",
      "Running sample 2800 out of 9000\n",
      "Running sample 2810 out of 9000\n",
      "Running sample 2820 out of 9000\n",
      "Running sample 2830 out of 9000\n",
      "Running sample 2840 out of 9000\n",
      "Running sample 2850 out of 9000\n",
      "Running sample 2860 out of 9000\n",
      "Running sample 2870 out of 9000\n",
      "Running sample 2880 out of 9000\n",
      "Running sample 2890 out of 9000\n",
      "Running sample 2900 out of 9000\n",
      "Running sample 2910 out of 9000\n",
      "Running sample 2920 out of 9000\n",
      "Running sample 2930 out of 9000\n",
      "Running sample 2940 out of 9000\n",
      "Running sample 2950 out of 9000\n",
      "Running sample 2960 out of 9000\n",
      "Running sample 2970 out of 9000\n",
      "Running sample 2980 out of 9000\n",
      "Running sample 2990 out of 9000\n",
      "Running sample 3000 out of 9000\n",
      "Running sample 3010 out of 9000\n",
      "Running sample 3020 out of 9000\n",
      "Running sample 3030 out of 9000\n",
      "Running sample 3040 out of 9000\n",
      "Running sample 3050 out of 9000\n",
      "Running sample 3060 out of 9000\n",
      "Running sample 3070 out of 9000\n",
      "Running sample 3080 out of 9000\n",
      "Running sample 3090 out of 9000\n",
      "Running sample 3100 out of 9000\n",
      "Running sample 3110 out of 9000\n",
      "Running sample 3120 out of 9000\n",
      "Running sample 3130 out of 9000\n",
      "Running sample 3140 out of 9000\n",
      "Running sample 3150 out of 9000\n",
      "Running sample 3160 out of 9000\n",
      "Running sample 3170 out of 9000\n",
      "Running sample 3180 out of 9000\n",
      "Running sample 3190 out of 9000\n",
      "Running sample 3200 out of 9000\n",
      "Running sample 3210 out of 9000\n",
      "Running sample 3220 out of 9000\n",
      "Running sample 3230 out of 9000\n",
      "Running sample 3240 out of 9000\n",
      "Running sample 3250 out of 9000\n",
      "Running sample 3260 out of 9000\n",
      "Running sample 3270 out of 9000\n",
      "Running sample 3280 out of 9000\n",
      "Running sample 3290 out of 9000\n",
      "Running sample 3300 out of 9000\n",
      "Running sample 3310 out of 9000\n",
      "Running sample 3320 out of 9000\n",
      "Running sample 3330 out of 9000\n",
      "Running sample 3340 out of 9000\n",
      "Running sample 3350 out of 9000\n",
      "Running sample 3360 out of 9000\n",
      "Running sample 3370 out of 9000\n",
      "Running sample 3380 out of 9000\n",
      "Running sample 3390 out of 9000\n",
      "Running sample 3400 out of 9000\n",
      "Running sample 3410 out of 9000\n",
      "Running sample 3420 out of 9000\n",
      "Running sample 3430 out of 9000\n",
      "Running sample 3440 out of 9000\n",
      "Running sample 3450 out of 9000\n",
      "Running sample 3460 out of 9000\n",
      "Running sample 3470 out of 9000\n",
      "Running sample 3480 out of 9000\n",
      "Running sample 3490 out of 9000\n",
      "Running sample 3500 out of 9000\n",
      "Running sample 3510 out of 9000\n",
      "Running sample 3520 out of 9000\n",
      "Running sample 3530 out of 9000\n",
      "Running sample 3540 out of 9000\n",
      "Running sample 3550 out of 9000\n",
      "Running sample 3560 out of 9000\n",
      "Running sample 3570 out of 9000\n",
      "Running sample 3580 out of 9000\n",
      "Running sample 3590 out of 9000\n",
      "Running sample 3600 out of 9000\n",
      "Running sample 3610 out of 9000\n",
      "Running sample 3620 out of 9000\n",
      "Running sample 3630 out of 9000\n",
      "Running sample 3640 out of 9000\n",
      "Running sample 3650 out of 9000\n",
      "Running sample 3660 out of 9000\n",
      "Running sample 3670 out of 9000\n",
      "Running sample 3680 out of 9000\n",
      "Running sample 3690 out of 9000\n",
      "Running sample 3700 out of 9000\n",
      "Running sample 3710 out of 9000\n",
      "Running sample 3720 out of 9000\n",
      "Running sample 3730 out of 9000\n",
      "Running sample 3740 out of 9000\n",
      "Running sample 3750 out of 9000\n",
      "Running sample 3760 out of 9000\n",
      "Running sample 3770 out of 9000\n",
      "Running sample 3780 out of 9000\n",
      "Running sample 3790 out of 9000\n",
      "Running sample 3800 out of 9000\n",
      "Running sample 3810 out of 9000\n",
      "Running sample 3820 out of 9000\n",
      "Running sample 3830 out of 9000\n",
      "Running sample 3840 out of 9000\n",
      "Running sample 3850 out of 9000\n",
      "Running sample 3860 out of 9000\n",
      "Running sample 3870 out of 9000\n",
      "Running sample 3880 out of 9000\n",
      "Running sample 3890 out of 9000\n",
      "Running sample 3900 out of 9000\n",
      "Running sample 3910 out of 9000\n",
      "Running sample 3920 out of 9000\n",
      "Running sample 3930 out of 9000\n",
      "Running sample 3940 out of 9000\n",
      "Running sample 3950 out of 9000\n",
      "Running sample 3960 out of 9000\n",
      "Running sample 3970 out of 9000\n",
      "Running sample 3980 out of 9000\n",
      "Running sample 3990 out of 9000\n",
      "Running sample 4000 out of 9000\n",
      "Running sample 4010 out of 9000\n",
      "Running sample 4020 out of 9000\n",
      "Running sample 4030 out of 9000\n",
      "Running sample 4040 out of 9000\n",
      "Running sample 4050 out of 9000\n",
      "Running sample 4060 out of 9000\n",
      "Running sample 4070 out of 9000\n",
      "Running sample 4080 out of 9000\n",
      "Running sample 4090 out of 9000\n",
      "Running sample 4100 out of 9000\n",
      "Running sample 4110 out of 9000\n",
      "Running sample 4120 out of 9000\n",
      "Running sample 4130 out of 9000\n",
      "Running sample 4140 out of 9000\n",
      "Running sample 4150 out of 9000\n",
      "Running sample 4160 out of 9000\n",
      "Running sample 4170 out of 9000\n",
      "Running sample 4180 out of 9000\n",
      "Running sample 4190 out of 9000\n",
      "Running sample 4200 out of 9000\n",
      "Running sample 4210 out of 9000\n",
      "Running sample 4220 out of 9000\n",
      "Running sample 4230 out of 9000\n",
      "Running sample 4240 out of 9000\n",
      "Running sample 4250 out of 9000\n",
      "Running sample 4260 out of 9000\n",
      "Running sample 4270 out of 9000\n",
      "Running sample 4280 out of 9000\n",
      "Running sample 4290 out of 9000\n",
      "Running sample 4300 out of 9000\n",
      "Running sample 4310 out of 9000\n",
      "Running sample 4320 out of 9000\n",
      "Running sample 4330 out of 9000\n",
      "Running sample 4340 out of 9000\n",
      "Running sample 4350 out of 9000\n",
      "Running sample 4360 out of 9000\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test\n",
    "\n",
    "Commençons par trouver le meilleur neurone pour chaque classe de MNIST."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "neuron_assignments = np.argmax(spikes, axis=0)\n",
    "print(\"Neuron assignments:\", neuron_assignments)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Testons à présent le réseau entrainé!"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Déasctiver la plasticité STDP\n",
    "input_synapse.plastic = False\n",
    "\n",
    "num_correct_output = 0\n",
    "old_spike_counts = np.zeros(len(excitatory_group))\n",
    "\n",
    "for i, (sample, label) in enumerate(zip(X_test, y_test)):\n",
    "    # Afficher régulièrement l'état d'avancement\n",
    "    if (i % 10) == 0:\n",
    "        print(\"Running sample %i out of %i\" % (i, len(X_test)))\n",
    "\n",
    "    excitatory_group.theta = 0 * units.mV\n",
    "\n",
    "    # Configurer le taux d'entrée\n",
    "    # ATTENTION, vous pouvez utiliser un autre type d'encodage\n",
    "    input_group.rates = sample / 4 * units.Hz\n",
    "\n",
    "    # Simuler le réseau\n",
    "    net.run(time_per_sample)\n",
    "\n",
    "    # Calculer le nombre de décharges pour l'échantillon\n",
    "    current_spike_count = e_monitor.count - old_spike_counts\n",
    "    # Gardons une copie du décompte de décharges pour pouvoir calculer le prochain\n",
    "    old_spike_counts = np.copy(e_monitor.count)\n",
    "\n",
    "    digit_spikes = np.zeros(10)\n",
    "    for neuron_idx in range(len(excitatory_group)):\n",
    "        digit_spikes[neuron_assignments[neuron_idx]] += current_spike_count[neuron_idx]\n",
    "\n",
    "    output_label = np.argmax(digit_spikes)\n",
    "\n",
    "    # Si la prédiction est correcte\n",
    "    if output_label == int(label):\n",
    "        num_correct_output += 1\n",
    "\n",
    "    # Laisser les variables retourner à leurs valeurs de repos\n",
    "    net.run(resting_time)\n",
    "\n",
    "\n",
    "print(\"The model accuracy is : %.3f\" % (num_correct_output / len(X_test)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "model_data = {\n",
    "    'weights': np.array(input_synapse.w),\n",
    "    'weight_indices_i': np.array(input_synapse.i),\n",
    "    'weight_indices_j': np.array(input_synapse.j),\n",
    "    'theta': np.array(excitatory_group.theta),\n",
    "    'labeled_neurons': neuron_assignments,\n",
    "    'spikes': spikes,\n",
    "    'num_excitatory': len(excitatory_group),\n",
    "}\n",
    "\n",
    "with open('stdp_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "print(\"✓ Modèle sauvegardé!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('stdp_model.pkl', 'rb') as f:\n",
    "    model_data = pickle.load(f)\n",
    "\n",
    "# Après avoir recréé le réseau:\n",
    "input_synapse.w = model_data['weights']\n",
    "excitatory_group.theta = model_data['theta']* units.mV\n",
    "labeled_neurons = model_data['labeled_neurons']\n",
    "spikes = model_data['spikes']\n",
    "print(\"✓ Modèle chargé!\")'''"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. Visualiser les poids\n",
    "weight_matrix = np.zeros((784, len(excitatory_group)))\n",
    "weight_matrix[input_synapse.i, input_synapse.j] = input_synapse.w\n",
    "\n",
    "plt.figure(figsize=(20, 20))  # Larger figure for more neurons\n",
    "for i in range(min(400, len(excitatory_group))):  # Changed from 100 to 400\n",
    "    plt.subplot(20, 20, i+1)  # Changed from 10x10 to 20x20 grid\n",
    "    plt.imshow(weight_matrix[:, i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "counts = Counter(neuron_assignments)\n",
    "for digit in range(10):\n",
    "    print(f\"Chiffre {digit}: {counts.get(digit, 0)} neurones\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(spikes.sum(axis=1))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.imshow(weight_matrix[:400, :400], cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
